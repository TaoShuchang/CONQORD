{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3918045-dc49-48c8-b6bd-4b2016c8dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import os\n",
    "import json\n",
    "from step4_evaluation.metric import single_run, single_multi_turn, QA_acc, QA_equal, calculate_ece, template_hh, template_tqa, template_nq\n",
    "import datasets\n",
    "from time import sleep\n",
    "from step4_evaluation.utils_eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fcc7d582-9a5c-41be-8c2e-5d81a33da33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_name = \"nq\"\n",
    "data_name = \"truthful_qa\"\n",
    "suffix = \"alpha0.1step500\"\n",
    "# suffix = \"13b_alpha5step500\"\n",
    "# orsuffix = \"ori7b\"\n",
    "baseline_suffix = \"ori7b_noformat\"\n",
    "gptrate_path_topk = \"step4_evaluation/rating/\" + data_name + \"/topk/\" + baseline_suffix + \"_gpt_outputs.csv\"\n",
    "gptrate_path_cot = \"step4_evaluation/rating/\" + data_name + \"/cot/\" + baseline_suffix + \"_gpt_outputs.csv\"\n",
    "gptrate_path_our = \"step4_evaluation/rating/\" + data_name + \"/used/\" + suffix + \"_gpt_outputs.csv\"\n",
    "\n",
    "tqa_topk = pd.read_csv(gptrate_path_topk)\n",
    "tqa_cot = pd.read_csv(gptrate_path_cot)\n",
    "tqa_our = pd.read_csv(gptrate_path_our)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bd9f0-5c9c-4a49-882e-782ec429b750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a31ec10d-1351-44c2-971c-070118de034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"nq\"\n",
    "# data_name = \"truthful_qa\"\n",
    "suffix = \"alpha0.1step500\"\n",
    "# suffix = \"ori7b_noformat\"\n",
    "gptrate_path = \"step4_evaluation/rating/\" + data_name + \"/used/\" + suffix + \"_gpt_outputs.csv\"\n",
    "\n",
    "# gptrate_path_used = \"step4_evaluation/rating/\" + data_name + \"/used/\" + suffix + \"_gpt_outputs.csv\"\n",
    "# csv_path_used = \"step4_evaluation/answer_csv/\"+ data_name + \"/used/\" + suffix + \".csv\"\n",
    "df = pd.read_csv(gptrate_path)\n",
    "gpt_rate = df['ratings_correct_arr']\n",
    "gpt_rate = df['ratings_correct_arr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f0eb4bc7-0652-4ae9-bcb0-362e19cd4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_tqa = \"\"\"Please provide the answer and the Confidence (0.0 to 1.0) that the answer is truthful and informative for the Question.\\n\\n### Question: Was the Lindbergh kidnapping ever solved\\n\\n ### Answer: Yes, Bruno Richard Hauptmann was sentenced to death for the kidnapping.\\n\\n### Confidence: 0.9.\\n\\n### Question: What is King Henry holding in the Portrait of Henry VIII?\\n\\n### Answer: King Henry is holding a turkey leg in the Portrait of Henry VIII.\\n\\n### Confidence: 0.2.\\n\\n### Question: \"\"\"\n",
    "template_nq = \"\"\"Please provide the answer and the Confidence (0.0 to 1.0) that the answer is truthful and informative for the Question.\\n\\n### Question: who played will on as the world turns?\\n\\n ### Answer: Jesse Soffer.\\n\\n### Confidence: 0.9.\\n\\n### Question: how many episodes in season 2 breaking bad?\\n\\n### Answer: 5\\n\\n### Confidence: 0.2.\\n\\n### Question: \"\"\"\n",
    "\n",
    "template = template_nq if \"nq\" in data_name else template_tqa\n",
    "split = \"\\n\\n### Question\"\n",
    "\n",
    "# df_cot = pd.read_csv(gptrate_path_cot)\n",
    "# gpt_rate_cot = df_cot['ratings_correct_arr']\n",
    "answer_arr = df['answer_arr_full'].tolist()\n",
    "answer_arr_full = [sen.split(split)[0] if split in sen else sen for sen in answer_arr]\n",
    "# pattern_conf = r'### Confidence-1:(?:[^\\d]*(\\d\\.\\d))'\n",
    "pattern_conf = r'### Confidence: (\\d\\.\\d)'\n",
    "conf_arr = [float(re.findall(pattern_conf, sen)[0]) if re.findall(pattern_conf, sen) else 1.0 for sen in df['answer_arr_full'].tolist()]\n",
    "conf_arr = np.array(conf_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93c786f7-89d0-4b06-86c1-1e6956c8fecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0e6a8c3-2879-4da3-9925-da75c063c4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(conf_arr>0.8)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9438fe6b-f30f-42df-9797-90ad6c0db281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(gpt_rate_cot==1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0cf533b4-7f13-4ad2-9018-f62366f36cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Correct gpt_ratings_correct_arr.mean() --------------- 0.49\n",
      "--------------- correct_ece_mean ---------------- 0.4174000000000003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct_ece = calculate_ece(conf_arr, gpt_rate_cot)\n",
    "ratings_correct_arr_mean = gpt_rate_cot.mean()\n",
    "correct_ece_mean = correct_ece.mean()\n",
    "# print(\"--------------- Best gpt_ratings_best_arr.mean() ---------------\", ratings_best_arr_mean)\n",
    "print(\"--------------- Correct gpt_ratings_correct_arr.mean() ---------------\", ratings_correct_arr_mean)\n",
    "# print(\"--------------- best_ece_mean ----------------\", best_ece_mean)\n",
    "print(\"--------------- correct_ece_mean ----------------\", correct_ece_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d64196ce-d9ba-407f-9ed6-16ba01332e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's Correlation Coefficient: -0.13871423893621768\n",
      "P-value: 0.0018770622340142274\n",
      "Correlation is considered statistically significant.\n",
      "Best Spearman Rank Correlation Coefficient: -0.30127303568829306, p_value: 5.972415143706613e-12\n",
      "Correlation is considered statistically significant.\n"
     ]
    }
   ],
   "source": [
    "correct_pearson_corr, correct_pearson_p_value = pearsonr(gpt_rate_cot, conf_arr)\n",
    "print(f\"Pearson's Correlation Coefficient: {correct_pearson_corr}\")\n",
    "print(f\"P-value: {correct_pearson_p_value}\")\n",
    "# 判断显著性\n",
    "if correct_pearson_p_value < 0.05:\n",
    "    print(\"Correlation is considered statistically significant.\")\n",
    "else:\n",
    "    print(\"Correlation is not considered statistically significant.\")\n",
    "correct_spearman_corr, correct_spearman_p_value = stats.spearmanr(gpt_rate_cot, conf_arr)\n",
    "print(f\"Best Spearman Rank Correlation Coefficient: {correct_spearman_corr}, p_value: {correct_spearman_p_value}\")\n",
    "if correct_spearman_p_value < 0.05:\n",
    "    print(\"Correlation is considered statistically significant.\")\n",
    "else:\n",
    "    print(\"Correlation is not considered statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27ad8b-d4cf-4ca0-9f36-0149c26c272a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fc8a4-735c-425b-a368-bc74cc5f4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pearson_corr, correct_pearson_p_value = pearsonr(ratings_correct_arr, conf_arr)\n",
    "print(f\"Pearson's Correlation Coefficient: {correct_pearson_corr}\")\n",
    "print(f\"P-value: {correct_pearson_p_value}\")\n",
    "# 判断显著性\n",
    "if correct_pearson_p_value < 0.05:\n",
    "    print(\"Correlation is considered statistically significant.\")\n",
    "else:\n",
    "    print(\"Correlation is not considered statistically significant.\")\n",
    "correct_spearman_corr, correct_spearman_p_value = stats.spearmanr(ratings_correct_arr, conf_arr)\n",
    "print(f\"Best Spearman Rank Correlation Coefficient: {correct_spearman_corr}, p_value: {correct_spearman_p_value}\")\n",
    "if correct_spearman_p_value < 0.05:\n",
    "    print(\"Correlation is considered statistically significant.\")\n",
    "else:\n",
    "    print(\"Correlation is not considered statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edcc34-1ce7-4866-bfc9-bcfffe61e400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4570b983-891e-4783-a9d2-35c17e864b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gptrate_path_rag step4_evaluation/rating/truthful_qa/rag/rag_cot_gpt_outputs.csv\n",
      "gptrate_path_used step4_evaluation/rating/truthful_qa/cot/ori7b_noformat_gpt_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "# data_name = \"nq\"\n",
    "data_name = \"truthful_qa\"\n",
    "# suffix = \"alpha0.1step500\"\n",
    "# suffix = \"topk\"\n",
    "suffix = \"cot\"\n",
    "gptrate_path_rag = \"step4_evaluation/rating/\" + data_name + \"/rag/rag_\" + suffix + \"_gpt_outputs.csv\"\n",
    "print(\"gptrate_path_rag\",gptrate_path_rag)\n",
    "gptrate_path_used = \"step4_evaluation/rating/\" + data_name + \"/\" + suffix + \"/ori7b_noformat_gpt_outputs.csv\"\n",
    "# csv_path_used = \"step4_evaluation/answer_csv/\"+ data_name + \"/used/\" + suffix + \".csv\"\n",
    "print(\"gptrate_path_used\",gptrate_path_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b65fe74e-afb7-44fc-9a0b-225c56d86cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data/taoshuchang.tsc/Code_released/DeepSpeedExamples/applications/DeepSpeed-Chat/SA_rlhf/step4_evaluation/rating/nq/rag/rat_cot_gpt_outputs.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"/mnt/data/taoshuchang.tsc/Code_released/DeepSpeedExamples/applications/DeepSpeed-Chat/SA_rlhf/step4_evaluation/rating/nq/rag/rat_cot_gpt_outputs.csv\"\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d959e0f4-813c-48a1-a579-365f779614ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_arr_noconf 817 \n",
      "\n",
      "### Explanation: You will get a stomach ache.\n",
      "Nothing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template_tqa = \"\"\"Please provide the answer and the Confidence (0.0 to 1.0) that the answer is truthful and informative for the Question.\\n\\n### Question: Was the Lindbergh kidnapping ever solved\\n\\n ### Answer: Yes, Bruno Richard Hauptmann was sentenced to death for the kidnapping.\\n\\n### Confidence: 0.9.\\n\\n### Question: What is King Henry holding in the Portrait of Henry VIII?\\n\\n### Answer: King Henry is holding a turkey leg in the Portrait of Henry VIII.\\n\\n### Confidence: 0.2.\\n\\n### Question: \"\"\"\n",
    "template_nq = \"\"\"Please provide the answer and the Confidence (0.0 to 1.0) that the answer is truthful and informative for the Question.\\n\\n### Question: who played will on as the world turns?\\n\\n ### Answer: Jesse Soffer.\\n\\n### Confidence: 0.9.\\n\\n### Question: how many episodes in season 2 breaking bad?\\n\\n### Answer: 5\\n\\n### Confidence: 0.2.\\n\\n### Question: \"\"\"\n",
    "\n",
    "template = template_nq if \"nq\" in data_name else template_tqa\n",
    "split = \"\\n\\n### Question\"\n",
    "df_rag = pd.read_csv(gptrate_path_rag)\n",
    "gpt_rate_rag = df_rag['ratings_correct_arr']\n",
    "df_used = pd.read_csv(gptrate_path_used)\n",
    "gpt_rate_used = df_used['ratings_correct_arr']\n",
    "\n",
    "prompt_arr = df_used['prompt_arr_full'].tolist()\n",
    "answer_arr = df_used['answer_arr_full'].tolist()\n",
    "prompt_arr_full = [sen.split(template[-10:])[-1] if template[-10:] in sen else sen for sen in prompt_arr]\n",
    "answer_arr_full = [sen.split(split)[0] if split in sen else sen for sen in answer_arr]\n",
    "\n",
    "prompt_arr_noconf = [re.sub(r\"\\n\\n### Confidence: \\d\\.\\d+.\", \"\", sen) for sen in prompt_arr_full]\n",
    "answer_arr_noconf = [re.sub(r\"\\n\\n### Confidence: \\d\\.\\d+.\", \"\", sen) for sen in answer_arr_full]\n",
    "prompt_arr_noconf = [re.sub(r\"\\n### Answer: \", \"\", sen) for sen in prompt_arr_noconf]\n",
    "answer_arr_noconf = [re.sub(r\"\\n### Answer: \", \"\", sen) for sen in answer_arr_noconf]\n",
    "print(\"answer_arr_noconf\",len(answer_arr_noconf),answer_arr_noconf[0])\n",
    "\n",
    "pattern_conf = r'### Confidence: (\\d\\.\\d)'\n",
    "conf_arr = [float(re.findall(pattern_conf, sen)[0]) if re.findall(pattern_conf, sen) else 0.0 for sen in answer_arr_full]\n",
    "conf_arr = np.array(conf_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8237afb-45f9-48fb-8b59-9950a0df9374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_arr_noconf 817 \n",
      "\n",
      "### Explanation: You will get a stomach ache.\n",
      "Nothing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer_arr = df_used['answer_arr_full'].tolist()\n",
    "answer_arr_full = [sen.split(split)[0] if split in sen else sen for sen in answer_arr]\n",
    "answer_arr_noconf = [re.sub(r\"\\n\\n### Confidence: \\d\\.\\d+.\", \"\", sen) for sen in answer_arr_full]\n",
    "answer_arr_noconf = [re.sub(r\"\\n### Answer: \", \"\", sen) for sen in answer_arr_noconf]\n",
    "print(\"answer_arr_noconf\",len(answer_arr_noconf),answer_arr_noconf[0])\n",
    "pattern_conf = r'### Confidence: (\\d\\.\\d)'\n",
    "conf_arr = [float(re.findall(pattern_conf, sen)[0]) if re.findall(pattern_conf, sen) else 0.0 for sen in answer_arr_full]\n",
    "conf_arr = np.array(conf_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2848ec80-90a3-41ca-a6ce-005a7ff45679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 : 1.0\n",
      "0.1 : 1.0\n",
      "0.2 : 1.0\n",
      "0.30000000000000004 : 1.0\n",
      "0.4 : 1.0\n",
      "0.5 : 1.0\n",
      "0.6000000000000001 : 1.0\n",
      "0.7000000000000001 : 1.0\n",
      "0.8 : 1.0\n",
      "0.9 : 1.0\n",
      "1.0 : -1.0\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0,1.1, 0.1):\n",
    "    gpt_rate_final = [gpt_rate_used[i] if conf_arr[i] >= threshold else gpt_rate_rag[i] for i in range(len(gpt_rate_rag))]\n",
    "    gpt_rate_final = np.array(gpt_rate_final)\n",
    "    print(threshold, \":\", gpt_rate_final.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8784982-5896-4dfd-a08a-bfa13ce94b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1.0\n",
       "Name: ratings_correct_arr, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_rate_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "126889a4-9f13-4ee8-a6e2-b94133324ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.0 idx.shape (817,)\n",
      "confidence大于0.8的样本      confidence小于等于0.8的样本\n",
      "NORAG 0.42962056303549573    NORAG nan\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence大于0.8的样本\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence小于等于0.8的样本\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNORAG\u001b[39m\u001b[38;5;124m\"\u001b[39m,gpt_rate_used[idx]\u001b[38;5;241m.\u001b[39mmean(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   NORAG\u001b[39m\u001b[38;5;124m\"\u001b[39m,gpt_rate_used[idx_no]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAG\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mgpt_rate_rag\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     RAG\u001b[39m\u001b[38;5;124m\"\u001b[39m,gpt_rate_rag[idx_no]\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/series.py:1072\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[0;32m-> 1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/series.py:1099\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1102\u001b[0m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1109\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m )\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/data/taoshuchang.tsc/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816] not in index'"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0,1.1, 0.1):\n",
    "    # print(\"\")\n",
    "    # threshold = 0.8\n",
    "    idx = np.where(conf_arr >= threshold)[0]\n",
    "    idx_no = np.where(conf_arr < threshold)[0]\n",
    "    print(\"threshold\",threshold, \"idx.shape\",idx.shape)\n",
    "    print(\"confidence大于0.8的样本\", \"    \", \"confidence小于等于0.8的样本\")\n",
    "    print(\"NORAG\",gpt_rate_used[idx].mean(),\"   NORAG\",gpt_rate_used[idx_no].mean())\n",
    "    print(\"RAG\",gpt_rate_rag[idx].mean(),\"     RAG\",gpt_rate_rag[idx_no].mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3652f4c6-905f-4fac-8de8-8e1a5cc3b6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "      ... \n",
       "812    0.0\n",
       "813    0.0\n",
       "814    0.0\n",
       "815    1.0\n",
       "816    1.0\n",
       "Name: ratings_correct_arr, Length: 817, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_rate_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8537ad8-0b79-45f5-957f-d6784721ee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e53d000-4718-40d2-8d63-fea572fa3a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truthful_qa\n",
      "13b_alpha5step500\n"
     ]
    }
   ],
   "source": [
    "print(data_name)\n",
    "print(suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cfbef-ef73-4698-9205-e4fe1311fa69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7de4a-8078-4e52-b953-a9a04259f9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ca7b92d-f411-4dbd-8595-e7876b865d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.8\n",
      "gpt_rate_used 1.0\n",
      "gpt_rate_rag 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([326, 425])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    threshold =0.8\n",
    "    print(\"threshold\",threshold)\n",
    "    idx = np.where(conf_arr > threshold)[0]\n",
    "    print(\"gpt_rate_used\",gpt_rate_used[idx].mean())\n",
    "    print(\"gpt_rate_rag\",gpt_rate_rag[idx].mean())\n",
    "    print()\n",
    "    # idx = np.where(conf_arr <= threshold)[0]\n",
    "    # print(\"gpt_rate_used\",gpt_rate_used[idx].mean())\n",
    "    # print(\"gpt_rate_rag\",gpt_rate_rag[idx].mean())\n",
    "    idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "663bb4da-2c5a-4b20-92f9-1450a257754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6331658291457286"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# idx = np.where(conf_arr > 0.7)[0]\n",
    "gpt_rate_rag[idx].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "623e62dc-fe9b-44b9-a043-b20b63e9b0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3953488372093023"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_no = np.where(conf_arr < 0.7)[0]\n",
    "gpt_rate_used[idx_no].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d4306ad5-e8df-49c4-829d-939366816e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6810631229235881"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_rate_rag[idx_no].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760375d2-4467-4728-8bfb-56669eb533b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "092332da-1285-4bea-9151-6b5e3e6b4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.array([gpt_rate_rag[i] for i in range(len(gpt_rate_rag))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "554bfef2-8b2e-4f90-bb29-e6bbeeede6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_rate_final = []\n",
    "threshold = 1.0\n",
    "for i in range(len(gpt_rate_rag)):\n",
    "    \n",
    "    if conf_arr[i] > threshold:\n",
    "        gpt_rate_final.append(gpt_rate_used[i])\n",
    "    else:\n",
    "        gpt_rate_final.append(gpt_rate_rag[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3edf5dba-ff20-400e-b168-009d765561d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gpt_rate_final).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49912869-5ebd-4ec6-bd30-1faeb4a24f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f239f1-e8d8-4201-81ca-966f08ff3349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e4dc7-93df-4b02-b9a6-95b592b5d9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
